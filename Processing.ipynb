{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pandas is a tool used to help us process dataframes/tables, which are csv-like\n",
    "#The Natural Language Toolkit is the package that helps us in the lemmatization and part-of-speech tagging\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 'DT')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NOTE: the nltk.download() was giving me trouble so I used: import nltk\n",
    "#Then: nltk.download('wordnet') and nltk.download('wordnet_ic')\n",
    "#To get the specific data packs we need\n",
    "\n",
    "#testing if it worked...\n",
    "\n",
    "#Another note: lemmatizer and stemmer seem not to be doing what I hoped\n",
    "#Might need to use VerbNet? Look into this next...\n",
    "wnl = WordNetLemmatizer()\n",
    "ps = PorterStemmer()\n",
    "wnl.lemmatize('dogs')\n",
    "ps.stem('is')\n",
    "text = [\"Rylund\",\"this\"]\n",
    "nltk.pos_tag([\"this\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This is a helper function that allows us to split up the text and make it uniform for processing\n",
    "def cleaner(word):\n",
    "    #This \"if\" line removes \"@\" from the end of words that have it\n",
    "    if \"@\" in word:\n",
    "        loc = word.find(\"@\")\n",
    "        word = word[:loc]\n",
    "\n",
    "    return word.replace(\",\",\"\").replace(\"(\",\"\").replace(\"\\\"\",\"\").replace(\")\",\"\").strip(r\" .?![?]\").split()\n",
    "\n",
    "#Helper funciton to map part-of-speech tags to something that our root-finding map \"wordnet\" can recognize\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def tag_helper(word,tag):\n",
    "    wntag = get_wordnet_pos(tag)\n",
    "    if wntag is None:# not supply tag in case of None\n",
    "        lemma = wnl.lemmatize(word)\n",
    "        tb_tag = \"\"\n",
    "    #assigning a variable to the english equivalent of our tags to be used later when we build the csv\n",
    "    else:\n",
    "        lemma = wnl.lemmatize(word, pos = wntag)\n",
    "        if wntag == wordnet.ADJ:\n",
    "            tb_tag = \"Adjective\"\n",
    "        elif wntag == wordnet.VERB:\n",
    "            tb_tag = \"Verb\"\n",
    "        elif wntag == wordnet.NOUN:\n",
    "            tb_tag = \"Noun\"\n",
    "        elif wntag == wordnet.ADV:\n",
    "            tb_tag = \"Adverb\"\n",
    "        elif wntag is None:\n",
    "            tb_tag = \"\"\n",
    "    return lemma, tb_tag\n",
    "\n",
    "def save_xls(list_dfs, xls_path):\n",
    "    writer = pd.ExcelWriter(xls_path)\n",
    "    for name, df in list_dfs:\n",
    "        df.to_excel(writer,'%s' % name)\n",
    "    writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Here we load in the data\n",
    "xls = pd.ExcelFile(\"Brent Corpus Samples_10_08_17.xlsx\")\n",
    "vocab_xls = pd.ExcelFile(\"Core Vocabulary_(Preschool).xlsx\")\n",
    "word_map_xlsx = pd.ExcelFile(\"word_map.xlsx\")\n",
    "\n",
    "#sheet_names stores all the names of the sheets from the excel file\n",
    "sheet_names = xls.sheet_names\n",
    "vocab_sheet_names = vocab_xls.sheet_names\n",
    "\n",
    "sheets = []\n",
    "for name in sheet_names:\n",
    "    if not name[-1].isalpha() and name != \"Sheet102\":\n",
    "        sheets.append((name,xls.parse(name)))\n",
    "\n",
    "#Note the spelling error in \"36 Univeresal Core\"... Entered in the CSV that way\n",
    "core_sheets = [(\"36 Core\", xls.parse('36 Univeresal Core')),\n",
    "              (\"100 Core\", xls.parse('100 Universal Core')),\n",
    "              (\"All Core\", xls.parse(\"All Universal Core\"))]\n",
    "\n",
    "preschool_sheets = []\n",
    "for name in vocab_sheet_names:\n",
    "    if name != \"All Three\":\n",
    "        preschool_sheets.append((name, vocab_xls.parse(name)))\n",
    "\n",
    "word_map_sheet = (\"Word Map\", word_map_xlsx.parse('word_map'))\n",
    "        \n",
    "core_36_list = [word.lower() for word in core_sheets[0][1][\"Words\"]]\n",
    "core_100_list = [word.lower() for word in core_sheets[1][1][\"Words\"]]\n",
    "core_all_list = [word.lower() for word in core_sheets[2][1][\"Words\"]]\n",
    "\n",
    "banajee_list = [word.lower() for word in preschool_sheets[0][1][\"Vocabulary\"]]\n",
    "beukelman_list = [word.lower() for word in preschool_sheets[1][1][\"Vocabulary\"]]\n",
    "marvin_list = [word.lower() for word in preschool_sheets[2][1][\"Vocabulary\"]]\n",
    "\n",
    "word_map = {key: value for key,value in zip(word_map_sheet[1][\"Lemmed Words\"], word_map_sheet[1][\"Map\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_corpus = []\n",
    "sheet_corpus = {}\n",
    "raw_word_count_by_sheet = {}\n",
    "lem_word_count_by_sheet = {}\n",
    "total_raw_word_count = {}\n",
    "total_lem_word_count = {}\n",
    "tagged_sheet = {}\n",
    "word_mapped = {}\n",
    "raw_mother_dict = {}\n",
    "raw_count_by_mother = {}\n",
    "lem_mother_dict = {}\n",
    "total_lemmed = []\n",
    "commonality = {}\n",
    "\n",
    "for name,sheet in sheets:\n",
    "    #print(name)\n",
    "    code = sheet['@Begin']\n",
    "    text = sheet['Unnamed: 1']\n",
    "    temp_raw_word_count = {}\n",
    "    temp_lem_word_count = {}\n",
    "    temp_corpus = []\n",
    "    abbrev = name[:2].lower()\n",
    "    if abbrev not in raw_count_by_mother:\n",
    "        raw_count_by_mother[abbrev] = {}\n",
    "    \n",
    "    for c,t in zip(code,text):\n",
    "        if c == \"*MOT:\":\n",
    "            \n",
    "            for word in cleaner(t):\n",
    "                if word[0].isalpha() and word[-1].isalpha(): #need to change this so that those words aren't just...\n",
    "                                                         #...thrown out.\n",
    "                    word = word.lower()\n",
    "                    #Making a big list of all the words used called \"corpus\"\n",
    "                    total_corpus.append(word)\n",
    "                    temp_corpus.append(word)\n",
    "                    #word_count counts the words for us\n",
    "                    if word not in temp_raw_word_count:\n",
    "                        temp_raw_word_count[word] = [0,0,0,0,0,0,0]\n",
    "                    temp_raw_word_count[word][0] = temp_raw_word_count.get(word)[0] + 1\n",
    "                    if word not in total_raw_word_count:\n",
    "                        total_raw_word_count[word] = [0,0,0,0,0,0,0]\n",
    "                    total_raw_word_count[word][0] = total_raw_word_count.get(word)[0] + 1\n",
    "                    if word not in raw_count_by_mother[abbrev]:\n",
    "                        raw_count_by_mother[abbrev][word] = [0,0,0,0,0,0,0]\n",
    "                    raw_count_by_mother[abbrev][word][0] = raw_count_by_mother[abbrev].get(word)[0] + 1\n",
    "                    \n",
    "                    if word in core_36_list:\n",
    "                        total_raw_word_count[word][1] = 1\n",
    "                    \n",
    "                    if word in core_100_list:\n",
    "                        total_raw_word_count[word][2] = 1\n",
    "                    \n",
    "                    if word in core_all_list:\n",
    "                        total_raw_word_count[word][3] = 1\n",
    "                        \n",
    "                    if word in banajee_list:\n",
    "                        total_raw_word_count[word][4] = 1\n",
    "\n",
    "                    if word in beukelman_list:\n",
    "                        total_raw_word_count[word][5] = 1\n",
    "\n",
    "                    if word in marvin_list:\n",
    "                        total_raw_word_count[word][6] = 1\n",
    "                    \n",
    "                    for i in range(1,7):\n",
    "                        temp_raw_word_count[word][i] = total_raw_word_count[word][i]\n",
    "                        raw_count_by_mother[abbrev][word][i] = total_raw_word_count[word][i]\n",
    "                    \n",
    "                    \n",
    "    raw_word_count_by_sheet[name] = temp_raw_word_count\n",
    "    lem_word_count_by_sheet[name] = temp_lem_word_count\n",
    "    sheet_corpus[name] = temp_corpus\n",
    "    tagged_sheet[name] = nltk.pos_tag(temp_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "total_lem_word_count = {}\n",
    "lem_word_count_by_mother = {}\n",
    "lem_count_by_sheet = {}\n",
    "for sheet, words in tagged_sheet.items():\n",
    "    abbrev = sheet[:2].lower()\n",
    "    if abbrev not in lem_word_count_by_mother:\n",
    "        lem_word_count_by_mother[abbrev] = {}\n",
    "    lem_count_by_sheet[sheet] = {}\n",
    "    \n",
    "    for word in words:\n",
    "        word,tag = word\n",
    "        lemma,tb_tag = tag_helper(word,tag)\n",
    "        if lemma in word_map:\n",
    "            lemma = word_map[lemma]\n",
    "        \n",
    "        if lemma not in total_lem_word_count:\n",
    "            total_lem_word_count[lemma] = [0,0,0,0,0,0,0]\n",
    "        total_lem_word_count[lemma][0] = total_lem_word_count.get(lemma)[0] + 1\n",
    "        \n",
    "        if lemma not in lem_word_count_by_mother[abbrev]:\n",
    "            lem_word_count_by_mother[abbrev][lemma] = [0,0,0,0,0,0,0]\n",
    "        lem_word_count_by_mother[abbrev][lemma][0] = lem_word_count_by_mother[abbrev].get(lemma)[0] + 1\n",
    "        \n",
    "        if lemma not in lem_count_by_sheet[sheet]:\n",
    "            lem_count_by_sheet[sheet][lemma] = [0,0,0,0,0,0,0]\n",
    "        lem_count_by_sheet[sheet][lemma][0] = lem_count_by_sheet[sheet].get(lemma)[0] + 1\n",
    "\n",
    "\n",
    "        if lemma in core_36_list:\n",
    "            total_lem_word_count[lemma][1] = 1\n",
    "\n",
    "        if lemma in core_100_list:\n",
    "            total_lem_word_count[lemma][2] = 1\n",
    "\n",
    "        if lemma in core_all_list:\n",
    "            total_lem_word_count[lemma][3] = 1\n",
    "\n",
    "        if lemma in banajee_list:\n",
    "            total_lem_word_count[lemma][4] = 1\n",
    "\n",
    "        if lemma in beukelman_list:\n",
    "            total_lem_word_count[lemma][5] = 1\n",
    "\n",
    "        if lemma in marvin_list:\n",
    "            total_lem_word_count[lemma][6] = 1\n",
    "                        \n",
    "        for i in range(1,7):\n",
    "            lem_word_count_by_mother[abbrev][lemma][i] = total_lem_word_count[lemma][i]\n",
    "            lem_count_by_sheet[sheet][lemma][i] = total_lem_word_count[lemma][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lem_count = sum([x[0] for x in total_lem_word_count.values()])\n",
    "total_lem = pd.Series([x[0] for x in total_lem_word_count.items()])\n",
    "total_lem_rel_freq = pd.Series([(x[1][0]/lem_count)*100 \n",
    "                          for x in total_lem_word_count.items()])\n",
    "total_lem_count = pd.Series([x[1][0] for x in total_lem_word_count.items()])\n",
    "total_lem_core_36 = pd.Series([x[1][1] for x in total_lem_word_count.items()])\n",
    "total_lem_core_100 = pd.Series([x[1][2] for x in total_lem_word_count.items()])\n",
    "total_lem_core_all = pd.Series([x[1][3] for x in total_lem_word_count.items()])\n",
    "total_lem_banajee = pd.Series([x[1][4] for x in total_lem_word_count.items()])\n",
    "total_lem_beukelman = pd.Series([x[1][5] for x in total_lem_word_count.items()])\n",
    "total_lem_marvin = pd.Series([x[1][6] for x in total_lem_word_count.items()])\n",
    "\n",
    "lem_total_df = pd.DataFrame({\"Lemmed Words\": total_lem, \"Count\": total_lem_count,\n",
    "                            \"Relative Freq\": total_lem_rel_freq, \"Core 36\": total_lem_core_36,\n",
    "                            \"Core 100\": total_lem_core_100, \"Core All\": total_lem_core_all,\n",
    "                            \"Banajee et al\": total_lem_banajee, \"Beukelman et al\": total_lem_beukelman,\n",
    "                            \"Marvin et al\": total_lem_marvin},\n",
    "                           columns = [\"Lemmed Words\", \"Count\", \"Relative Freq\",\n",
    "                                     \"Core 36\", \"Core 100\", \"Core All\", \"Banajee et al\",\n",
    "                                     \"Beukelman et al\", \"Marvin et al\"])\n",
    "lem_total_df.reset_index().drop(\"index\", axis = 1).sort_values(\"Relative Freq\")\n",
    "lem_total_df.to_excel(\"Lem Corpus 11_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lem_mother_dfs = []\n",
    "for mother,value in lem_word_count_by_mother.items():\n",
    "    current = value\n",
    "    lems = pd.Series([x[0] for x in current.items()])\n",
    "    lem_count = sum([x[0] for x in current.values()])\n",
    "    lem_rel_freq = pd.Series([(x[1][0]/lem_count)*100 \n",
    "                          for x in current.items()])\n",
    "    lem_count = pd.Series([x[1][0] for x in current.items()])\n",
    "    lem_core_36 = pd.Series([x[1][1] for x in current.items()])\n",
    "    lem_core_100 = pd.Series([x[1][2] for x in current.items()])\n",
    "    lem_core_all = pd.Series([x[1][3] for x in current.items()])\n",
    "    lem_banajee = pd.Series([x[1][4] for x in current.items()])\n",
    "    lem_beukelman = pd.Series([x[1][5] for x in current.items()])\n",
    "    lem_marvin = pd.Series([x[1][6] for x in current.items()])\n",
    "    temp_df = pd.DataFrame({\"Lemmed Words\": lems, \"Count\": lem_count,\n",
    "                            \"Relative Freq\": lem_rel_freq, \"Core 36\": lem_core_36,\n",
    "                            \"Core 100\": lem_core_100, \"Core All\": lem_core_all,\n",
    "                            \"Banajee et al\": lem_banajee, \"Beukelman et al\": lem_beukelman,\n",
    "                            \"Marvin et al\": lem_marvin},\n",
    "                           columns = [\"Lemmed Words\", \"Count\", \"Relative Freq\",\n",
    "                                     \"Core 36\", \"Core 100\", \"Core All\", \"Banajee et al\",\n",
    "                                     \"Beukelman et al\", \"Marvin et al\"])\n",
    "    temp_df.reset_index().drop(\"index\", axis = 1).sort_values(\"Relative Freq\")\n",
    "    lem_mother_dfs.append((mother,temp_df))\n",
    "\n",
    "save_xls(lem_mother_dfs, \"Lem by Mother 11_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lem_sheet_dfs = []\n",
    "for sheet,value in lem_count_by_sheet.items():\n",
    "    current = value\n",
    "    lems = pd.Series([x[0] for x in current.items()])\n",
    "    lem_count = sum([x[0] for x in current.values()])\n",
    "    lem_rel_freq = pd.Series([(x[1][0]/lem_count)*100 \n",
    "                          for x in current.items()])\n",
    "    lem_count = pd.Series([x[1][0] for x in current.items()])\n",
    "    lem_core_36 = pd.Series([x[1][1] for x in current.items()])\n",
    "    lem_core_100 = pd.Series([x[1][2] for x in current.items()])\n",
    "    lem_core_all = pd.Series([x[1][3] for x in current.items()])\n",
    "    lem_banajee = pd.Series([x[1][4] for x in current.items()])\n",
    "    lem_beukelman = pd.Series([x[1][5] for x in current.items()])\n",
    "    lem_marvin = pd.Series([x[1][6] for x in current.items()])\n",
    "    temp_df = pd.DataFrame({\"Lemmed Words\": lems, \"Count\": lem_count,\n",
    "                            \"Relative Freq\": lem_rel_freq, \"Core 36\": lem_core_36,\n",
    "                            \"Core 100\": lem_core_100, \"Core All\": lem_core_all,\n",
    "                            \"Banajee et al\": lem_banajee, \"Beukelman et al\": lem_beukelman,\n",
    "                            \"Marvin et al\": lem_marvin},\n",
    "                           columns = [\"Lemmed Words\", \"Count\", \"Relative Freq\",\n",
    "                                     \"Core 36\", \"Core 100\", \"Core All\", \"Banajee et al\",\n",
    "                                     \"Beukelman et al\", \"Marvin et al\"])\n",
    "    temp_df.reset_index().drop(\"index\", axis = 1).sort_values(\"Relative Freq\")\n",
    "    lem_sheet_dfs.append((sheet,temp_df))\n",
    "\n",
    "save_xls(lem_sheet_dfs, \"Lem by Sessions 11_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no more of that...\n"
     ]
    }
   ],
   "source": [
    "raw_count = sum([x[0] for x in total_raw_word_count.values()])\n",
    "total_raw = pd.Series([x[0] for x in total_raw_word_count.items()])\n",
    "total_raw_count = pd.Series([x[1][0] for x in total_raw_word_count.items()])\n",
    "raw_rel_freq = pd.Series([(x[1][0]/raw_count)*100 \n",
    "                          for x  in total_raw_word_count.items()])\n",
    "raw_core_36 = pd.Series([x[1][1] for x in total_raw_word_count.items()])\n",
    "raw_core_100 = pd.Series([x[1][2] for x in total_raw_word_count.items()])\n",
    "raw_core_all = pd.Series([x[1][3] for x in total_raw_word_count.items()])\n",
    "raw_banajee = pd.Series([x[1][4] for x in total_raw_word_count.items()])\n",
    "raw_beukelman = pd.Series([x[1][5] for x in total_raw_word_count.items()])\n",
    "raw_marvin = pd.Series([x[1][6] for x in total_raw_word_count.items()])\n",
    "\n",
    "raw_total_df = pd.DataFrame({\"Raw Words\": total_raw, \"Count\": total_raw_count,\n",
    "                            \"Relative Freq\": raw_rel_freq, \"Core 36\": raw_core_36,\n",
    "                            \"Core 100\": raw_core_100, \"Core All\": raw_core_all,\n",
    "                            \"Banajee et al\": raw_banajee, \"Beukelman et al\": raw_beukelman,\n",
    "                            \"Marvin et al\": raw_marvin},\n",
    "                           columns = [\"Raw Words\", \"Count\", \"Relative Freq\",\n",
    "                                     \"Core 36\", \"Core 100\", \"Core All\",\n",
    "                                     \"Banajee et al\", \"Beukelman et al\", \"Marvin et al\"])\n",
    "raw_total_df.reset_index().drop(\"index\", axis = 1).sort_values(\"Relative Freq\")\n",
    "raw_total_df.to_excel(\"Raw Corpus 11_5.xlsx\")\n",
    "print(\"no more of that...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "commonality = {}\n",
    "for mother, values in raw_count_by_mother.items():\n",
    "    for word, count in values.items():\n",
    "        if word not in commonality:\n",
    "            commonality[word] = 0\n",
    "        commonality[word] = commonality[word] + 1\n",
    "commonality_word = pd.Series([x[0] for x in commonality.items()])\n",
    "commonality_count = pd.Series([x for x in commonality.values()])\n",
    "common_df = pd.DataFrame({\"Words\": commonality_word, \"Counts\": commonality_count},\n",
    "                        columns = [\"Words\", \"Count\"])\n",
    "#common_df = pd.DataFrame.from_dict(commonality, orient = \"index\")\n",
    "#common_df.to_excel(\"Commonality Across Mothers.xlsx\")\n",
    "\n",
    "new_raw_count_by_mother = {abbrev[0]: {} for abbrev in raw_count_by_mother.items()}\n",
    "for mom, dic in raw_count_by_mother.items():\n",
    "    for word, count in dic.items():\n",
    "        new_raw_count_by_mother[mom][word] = [count[0], count[1], count[2], count[3],\n",
    "                                                 count[4], count[5], count[6], commonality[word]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "raw_mother_dfs = []\n",
    "#changing to new_raw_count_by_mother\n",
    "for mother,value in new_raw_count_by_mother.items():\n",
    "    current = value\n",
    "    raws = pd.Series([x[0] for x in current.items()])\n",
    "    raw_count = sum([x[0] for x in current.values()])\n",
    "    raw_rel_freq = pd.Series([(x[1][0]/raw_count)*100 \n",
    "                          for x in current.items()])\n",
    "    raw_count = pd.Series([x[1][0] for x in current.items()])\n",
    "    raw_core_36 = pd.Series([x[1][1] for x in current.items()])\n",
    "    raw_core_100 = pd.Series([x[1][2] for x in current.items()])\n",
    "    raw_core_all = pd.Series([x[1][3] for x in current.items()])\n",
    "    raw_banajee = pd.Series([x[1][4] for x in current.items()])\n",
    "    raw_beukelman = pd.Series([x[1][5] for x in current.items()])\n",
    "    raw_marvin = pd.Series([x[1][6] for x in current.items()])\n",
    "    common = pd.Series([x[1][7] for x in current.items()])\n",
    "    temp_df = pd.DataFrame({\"Raw Words\": raws, \"Count\": raw_count,\n",
    "                            \"Relative Freq\": raw_rel_freq, \"Core 36\": raw_core_36,\n",
    "                            \"Core 100\": raw_core_100, \"Core All\": raw_core_all,\n",
    "                            \"Banajee et al\": raw_banajee, \"Beukelman et al\": raw_beukelman,\n",
    "                            \"Marvin et al\": raw_marvin, \"Commonality\": common},\n",
    "                           columns = [\"Raw Words\", \"Count\", \"Relative Freq\",\n",
    "                                     \"Core 36\", \"Core 100\", \"Core All\", \"Banajee et al\",\n",
    "                                     \"Beukelman et al\", \"Marvin et al\", \"Commonality\"])\n",
    "    raw_mother_dfs.append((mother,temp_df))\n",
    "    \n",
    "\n",
    "\n",
    "save_xls(raw_mother_dfs, \"Raw by Mother 12_4.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_sheet_dfs = []\n",
    "for session,value in raw_word_count_by_sheet.items():\n",
    "    current = value\n",
    "    raws = pd.Series([x[0] for x in current.items()])\n",
    "    raw_count = sum([x[0] for x in current.values()])\n",
    "    raw_rel_freq = pd.Series([(x[1][0]/raw_count)*100 \n",
    "                          for x in current.items()])\n",
    "    raw_count = pd.Series([x[1][0] for x in current.items()])\n",
    "    raw_core_36 = pd.Series([x[1][1] for x in current.items()])\n",
    "    raw_core_100 = pd.Series([x[1][2] for x in current.items()])\n",
    "    raw_core_all = pd.Series([x[1][3] for x in current.items()])\n",
    "    raw_banajee = pd.Series([x[1][4] for x in current.items()])\n",
    "    raw_beukelman = pd.Series([x[1][5] for x in current.items()])\n",
    "    raw_marvin = pd.Series([x[1][6] for x in current.items()])\n",
    "    temp_df = pd.DataFrame({\"Raw Words\": raws, \"Count\": raw_count,\n",
    "                            \"Relative Freq\": raw_rel_freq, \"Core 36\": raw_core_36,\n",
    "                            \"Core 100\": raw_core_100, \"Core All\": raw_core_all,\n",
    "                            \"Banajee et al\": raw_banajee, \"Beukelman et al\": raw_beukelman,\n",
    "                            \"Marvin et al\": raw_marvin},\n",
    "                           columns = [\"Raw Words\", \"Count\", \"Relative Freq\",\n",
    "                                     \"Core 36\", \"Core 100\", \"Core All\", \"Banajee et al\",\n",
    "                                     \"Beukelman et al\", \"Marvin et al\"])\n",
    "    raw_sheet_dfs.append((session,temp_df))\n",
    "\n",
    "save_xls(raw_sheet_dfs, \"Raw by Session 11_5.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267204\n",
      "267204\n",
      "267204\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for key,value in lem_word_count_by_mother.items():\n",
    "    for word,count in value.items():\n",
    "            counter += count[0]\n",
    "print(counter)\n",
    "new_count = 0\n",
    "for key,value in total_lem_word_count.items():\n",
    "    new_count += value[0]\n",
    "print(new_count)\n",
    "new_new = 0\n",
    "for key,value in lem_count_by_sheet.items():\n",
    "    for word,count in value.items():\n",
    "        new_new += count[0]\n",
    "print(new_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267204\n",
      "267204\n",
      "267204\n",
      "267204\n"
     ]
    }
   ],
   "source": [
    "new_new = 0\n",
    "print(len(total_corpus))\n",
    "counter = 0\n",
    "for count in total_raw_word_count.values():\n",
    "    counter += count[0]\n",
    "print(counter)\n",
    "new_counter = 0\n",
    "for key,value in raw_count_by_mother.items():\n",
    "    for word,count in value.items():\n",
    "        new_counter += count[0]\n",
    "print(new_counter)\n",
    "new_new_counter = 0\n",
    "for key,value in raw_word_count_by_sheet.items():\n",
    "    for word,count in value.items():\n",
    "        new_new_counter += count[0]\n",
    "print(new_new_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Note total_lem_word_count's list for value goes like this:\n",
    "# [count, 36 yes/no, 100 yes/no, all yes/no] for universal core binary\n",
    "total_lem_word_count = {}\n",
    "total_lemmed = []\n",
    "\n",
    "for word, tag in total_tagged:\n",
    "    \n",
    "    lemma, tb_tag = tag_helper(word,tag)\n",
    "    \n",
    "    if lemma in word_map:\n",
    "        lemma = word_map[lemma]\n",
    "    \n",
    "    #builing out lemmed here\n",
    "    total_lemmed.append((word,lemma,tb_tag))\n",
    "    #builing out the count here\n",
    "    if lemma not in total_lem_word_count:\n",
    "        total_lem_word_count[lemma] = [0,0,0,0,0,0,0]\n",
    "    total_lem_word_count[lemma][0] = total_lem_word_count.get(lemma)[0] + 1\n",
    "    \n",
    "    if lemma in core_36_list:\n",
    "        total_lem_word_count[lemma][1] = 1\n",
    "    \n",
    "    if lemma in core_100_list:\n",
    "        total_lem_word_count[lemma][2] = 1\n",
    "    \n",
    "    if lemma in core_all_list:\n",
    "        total_lem_word_count[lemma][3] = 1\n",
    "        \n",
    "    if lemma in banajee_list:\n",
    "        total_lem_word_count[lemma][4] = 1\n",
    "        \n",
    "    if lemma in beukelman_list:\n",
    "        total_lem_word_count[lemma][5] = 1\n",
    "        \n",
    "    if lemma in marvin_list:\n",
    "        total_lem_word_count[lemma][6] = 1\n",
    "\n",
    "\n",
    "lem_count = sum([x[0] for x in total_lem_word_count.values()])\n",
    "total_lem = pd.Series([x[0] for x in total_lem_word_count.items()])\n",
    "lem_rel_freq = pd.Series([(x[1][0]/lem_count)*100 \n",
    "                          for x in total_lem_word_count.items()])\n",
    "total_lem_count = pd.Series([x[1][0] for x in total_lem_word_count.items()])\n",
    "lem_core_36 = pd.Series([x[1][1] for x in total_lem_word_count.items()])\n",
    "lem_core_100 = pd.Series([x[1][2] for x in total_lem_word_count.items()])\n",
    "lem_core_all = pd.Series([x[1][3] for x in total_lem_word_count.items()])\n",
    "lem_banajee = pd.Series([x[1][4] for x in total_lem_word_count.items()])\n",
    "lem_beukelman = pd.Series([x[1][5] for x in total_lem_word_count.items()])\n",
    "lem_marvin = pd.Series([x[1][6] for x in total_lem_word_count.items()])\n",
    "\n",
    "lem_total_df = pd.DataFrame({\"Lemmed Words\": total_lem, \"Count\": total_lem_count,\n",
    "                            \"Relative Freq\": lem_rel_freq, \"Core 36\": lem_core_36,\n",
    "                            \"Core 100\": lem_core_100, \"Core All\": lem_core_all,\n",
    "                            \"Banajee et al\": lem_banajee, \"Beukelman et al\": lem_beukelman,\n",
    "                            \"Marvin et al\": lem_marvin},\n",
    "                           columns = [\"Lemmed Words\", \"Count\", \"Relative Freq\",\n",
    "                                     \"Core 36\", \"Core 100\", \"Core All\", \"Banajee et al\",\n",
    "                                     \"Beukelman et al\", \"Marvin et al\"])\n",
    "lem_total_df.reset_index().drop(\"index\", axis = 1).sort_values(\"Relative Freq\")\n",
    "\n",
    "lem_total_df.to_csv(\"Corpus - Lemmed words 11_5.csv\")\n",
    "\n",
    "\n",
    "raw_count = sum([x[0] for x in total_raw_word_count.values()])\n",
    "total_raw = pd.Series([x[0] for x in total_raw_word_count.items()])\n",
    "total_raw_count = pd.Series([x[1][0] for x in total_raw_word_count.items()])\n",
    "raw_rel_freq = pd.Series([(x[1][0]/raw_count)*100 \n",
    "                          for x  in total_raw_word_count.items()])\n",
    "raw_core_36 = pd.Series([x[1][1] for x in total_raw_word_count.items()])\n",
    "raw_core_100 = pd.Series([x[1][2] for x in total_raw_word_count.items()])\n",
    "raw_core_all = pd.Series([x[1][3] for x in total_raw_word_count.items()])\n",
    "raw_banajee = pd.Series([x[1][4] for x in total_raw_word_count.items()])\n",
    "raw_beukelman = pd.Series([x[1][5] for x in total_raw_word_count.items()])\n",
    "raw_marvin = pd.Series([x[1][6] for x in total_raw_word_count.items()])\n",
    "\n",
    "raw_total_df = pd.DataFrame({\"Raw Words\": total_raw, \"Count\": total_raw_count,\n",
    "                            \"Relative Freq\": raw_rel_freq, \"Core 36\": raw_core_36,\n",
    "                            \"Core 100\": raw_core_100, \"Core All\": raw_core_all,\n",
    "                            \"Banajee et al\": raw_banajee, \"Beukelman et al\": raw_beukelman,\n",
    "                            \"Marvin et al\": raw_marvin},\n",
    "                           columns = [\"Raw Words\", \"Count\", \"Relative Freq\",\n",
    "                                     \"Core 36\", \"Core 100\", \"Core All\",\n",
    "                                     \"Banajee et al\", \"Beukelman et al\", \"Marvin et al\"])\n",
    "raw_total_df.reset_index().drop(\"index\", axis = 1).sort_values(\"Relative Freq\")\n",
    "\n",
    "raw_total_df.to_csv(\"Corpus - Raw words 11_5.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
